{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(data['data'],columns=data['feature_names'])\n",
    "Y = pd.DataFrame(data['target'],columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)\n",
       "0                  5.1               3.5\n",
       "1                  4.9               3.0\n",
       "2                  4.7               3.2\n",
       "3                  4.6               3.1\n",
       "4                  5.0               3.6\n",
       "5                  5.4               3.9\n",
       "6                  4.6               3.4\n",
       "7                  5.0               3.4\n",
       "8                  4.4               2.9\n",
       "9                  4.9               3.1\n",
       "10                 5.4               3.7\n",
       "11                 4.8               3.4\n",
       "12                 4.8               3.0\n",
       "13                 4.3               3.0\n",
       "14                 5.8               4.0\n",
       "15                 5.7               4.4\n",
       "16                 5.4               3.9\n",
       "17                 5.1               3.5\n",
       "18                 5.7               3.8\n",
       "19                 5.1               3.8\n",
       "20                 5.4               3.4\n",
       "21                 5.1               3.7\n",
       "22                 4.6               3.6\n",
       "23                 5.1               3.3\n",
       "24                 4.8               3.4\n",
       "25                 5.0               3.0\n",
       "26                 5.0               3.4\n",
       "27                 5.2               3.5\n",
       "28                 5.2               3.4\n",
       "29                 4.7               3.2\n",
       "..                 ...               ...\n",
       "120                6.9               3.2\n",
       "121                5.6               2.8\n",
       "122                7.7               2.8\n",
       "123                6.3               2.7\n",
       "124                6.7               3.3\n",
       "125                7.2               3.2\n",
       "126                6.2               2.8\n",
       "127                6.1               3.0\n",
       "128                6.4               2.8\n",
       "129                7.2               3.0\n",
       "130                7.4               2.8\n",
       "131                7.9               3.8\n",
       "132                6.4               2.8\n",
       "133                6.3               2.8\n",
       "134                6.1               2.6\n",
       "135                7.7               3.0\n",
       "136                6.3               3.4\n",
       "137                6.4               3.1\n",
       "138                6.0               3.0\n",
       "139                6.9               3.1\n",
       "140                6.7               3.1\n",
       "141                6.9               3.1\n",
       "142                5.8               2.7\n",
       "143                6.8               3.2\n",
       "144                6.7               3.3\n",
       "145                6.7               3.0\n",
       "146                6.3               2.5\n",
       "147                6.5               3.0\n",
       "148                6.2               3.4\n",
       "149                5.9               3.0\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(columns=['petal length (cm)'],inplace=True)\n",
    "X.drop(columns=['petal width (cm)'],inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.88914552,  1.66004251],\n",
       "       [-1.2574912 , -0.11263915],\n",
       "       [-1.50305498,  1.21687209],\n",
       "       [ 1.07536473,  0.55211647],\n",
       "       [-0.39801796, -0.99897997],\n",
       "       [ 1.19814662, -0.55580956],\n",
       "       [ 0.33867338, -0.99897997],\n",
       "       [-0.27523607, -0.11263915],\n",
       "       [-0.39801796,  2.54638333],\n",
       "       [-0.15245418, -0.33422435],\n",
       "       [-0.27523607, -1.22056518],\n",
       "       [-1.62583687, -1.66373559],\n",
       "       [ 0.21589149, -0.33422435],\n",
       "       [ 0.95258283, -0.33422435],\n",
       "       [ 0.0931096 , -0.11263915],\n",
       "       [-1.01192742,  0.55211647],\n",
       "       [-1.01192742,  0.99528689],\n",
       "       [-1.01192742,  0.99528689],\n",
       "       [ 1.32092851,  0.10894606],\n",
       "       [ 0.70701905, -0.77739477],\n",
       "       [-0.15245418, -1.22056518],\n",
       "       [ 2.54874741,  1.66004251],\n",
       "       [-1.01192742, -0.11263915],\n",
       "       [-1.74861876, -0.33422435],\n",
       "       [ 0.21589149, -1.8853208 ],\n",
       "       [-0.39801796, -1.44215039],\n",
       "       [-1.13470931, -1.44215039],\n",
       "       [-1.2574912 ,  0.77370168],\n",
       "       [-1.01192742,  0.33053127],\n",
       "       [ 1.07536473, -0.11263915],\n",
       "       [ 0.58423716,  0.55211647],\n",
       "       [-0.52079985,  1.88162771],\n",
       "       [-0.15245418, -0.55580956],\n",
       "       [ 0.21589149, -0.11263915],\n",
       "       [-0.15245418, -0.99897997],\n",
       "       [-1.2574912 ,  0.77370168],\n",
       "       [ 1.07536473,  0.55211647],\n",
       "       [ 0.58423716, -1.66373559],\n",
       "       [-0.15245418, -0.55580956],\n",
       "       [-0.52079985,  1.88162771],\n",
       "       [ 0.95258283, -0.11263915],\n",
       "       [ 1.19814662,  0.33053127],\n",
       "       [ 2.30318363, -0.55580956],\n",
       "       [-0.88914552,  1.66004251],\n",
       "       [-0.27523607, -0.55580956],\n",
       "       [ 0.82980094, -0.11263915],\n",
       "       [-0.27523607, -0.77739477],\n",
       "       [ 0.33867338, -0.55580956],\n",
       "       [-0.76636363,  2.32479813],\n",
       "       [-1.50305498,  0.77370168],\n",
       "       [-0.88914552,  1.66004251],\n",
       "       [-0.88914552,  0.77370168],\n",
       "       [ 0.82980094, -0.55580956],\n",
       "       [-0.02967229, -0.77739477],\n",
       "       [-0.02967229, -0.77739477],\n",
       "       [ 2.30318363, -0.99897997],\n",
       "       [-1.13470931,  0.10894606],\n",
       "       [ 0.46145527, -0.55580956],\n",
       "       [ 1.07536473,  0.10894606],\n",
       "       [-0.39801796,  0.99528689],\n",
       "       [ 0.58423716, -0.77739477],\n",
       "       [-1.74861876, -0.11263915],\n",
       "       [-1.38027309,  0.33053127],\n",
       "       [ 0.58423716, -0.33422435],\n",
       "       [-1.01192742,  0.77370168],\n",
       "       [-0.27523607, -0.33422435],\n",
       "       [-0.52079985,  1.4384573 ],\n",
       "       [-1.50305498,  0.33053127],\n",
       "       [-0.15245418, -0.11263915],\n",
       "       [-0.76636363,  0.77370168],\n",
       "       [-0.02967229, -0.55580956],\n",
       "       [ 0.58423716, -1.22056518],\n",
       "       [-0.88914552,  1.4384573 ],\n",
       "       [-1.2574912 , -0.11263915],\n",
       "       [-0.52079985,  0.77370168],\n",
       "       [-0.52079985,  0.77370168],\n",
       "       [ 1.07536473,  0.10894606],\n",
       "       [ 0.33867338, -0.33422435],\n",
       "       [ 1.19814662, -0.11263915],\n",
       "       [ 0.33867338, -0.11263915],\n",
       "       [-0.02967229, -0.99897997],\n",
       "       [-0.15245418,  2.98955374],\n",
       "       [ 1.81205607, -0.33422435],\n",
       "       [-0.39801796, -1.44215039],\n",
       "       [ 0.82980094,  0.33053127],\n",
       "       [-0.02967229, -0.77739477],\n",
       "       [ 0.70701905, -0.55580956],\n",
       "       [ 1.93483796, -0.55580956],\n",
       "       [-0.27523607, -0.11263915],\n",
       "       [-1.01192742,  0.77370168],\n",
       "       [ 0.46145527,  0.77370168],\n",
       "       [-1.74861876,  0.33053127],\n",
       "       [ 0.82980094, -0.11263915],\n",
       "       [ 0.33867338, -0.55580956],\n",
       "       [ 1.68927418,  0.33053127],\n",
       "       [-0.39801796, -1.66373559],\n",
       "       [ 0.46145527, -1.8853208 ],\n",
       "       [ 0.70701905,  0.33053127],\n",
       "       [-1.13470931,  0.10894606],\n",
       "       [ 2.30318363, -0.11263915],\n",
       "       [ 1.56649229, -0.11263915],\n",
       "       [-0.02967229,  2.10321292],\n",
       "       [-0.15245418,  1.66004251],\n",
       "       [-0.76636363, -0.77739477],\n",
       "       [-0.88914552, -1.22056518],\n",
       "       [-1.01192742, -1.66373559],\n",
       "       [ 0.0931096 , -0.11263915],\n",
       "       [-1.87140065, -0.11263915],\n",
       "       [ 1.07536473, -1.22056518],\n",
       "       [ 0.70701905,  0.33053127],\n",
       "       [-1.01192742, -2.32849121],\n",
       "       [ 0.21589149,  0.77370168],\n",
       "       [ 1.68927418,  1.21687209],\n",
       "       [-0.64358174,  1.4384573 ],\n",
       "       [ 0.82980094, -0.11263915],\n",
       "       [ 0.21589149, -0.77739477],\n",
       "       [ 0.58423716,  0.77370168],\n",
       "       [ 0.58423716, -0.55580956],\n",
       "       [ 2.18040174, -0.11263915],\n",
       "       [-0.52079985, -0.11263915]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#æ¨™æº–åŒ–\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x=StandardScaler()\n",
    "X_train_std=sc_x.fit_transform(X_train)\n",
    "X_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiwii\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "    markers=('s', 'x', 'o', '^', 'v')\n",
    "    colors=('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "                                 \n",
    "    x1_min, x1_max = X[:,0].min() - 1, X[:, 0].max()+ 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    z = z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    \n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0],\n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8,\n",
    "                    c=colors [idx],\n",
    "                    marker=markers[idx],\n",
    "                    label=cl,\n",
    "                    edgecolor='black')\n",
    "    if test_idx:\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "        plt.scatter(x_test [:, 0],\n",
    "                    x_test[:, 1],\n",
    "                    c='',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100,\n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-20cda9d7fd0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#plot_decision_regions(X_train_std,y_train,classifier=gnb,test_idx=range(105,150))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplot_decision_regions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sepal length [standardized]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sepal width [standardized]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-2f70f7aaa199>\u001b[0m in \u001b[0;36mplot_decision_regions\u001b[1;34m(X, y, classifier, test_idx, resolution)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         plt.scatter(x=X[y == cl, 0],\n\u001b[0m\u001b[0;32m     21\u001b[0m                     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#è®“test_indexèƒ½å¤ è·ŸåŽŸæœ¬æ•¸å€¼ç–Šåœ¨ä¸€èµ·\n",
    "#X_combined_std = np.vstack((X_train_std,X_test_std))\n",
    "#y_combined_std\n",
    "#plot_decision_regions(X_train_std,y_train,classifier=gnb,test_idx=range(105,150))\n",
    "\n",
    "plot_decision_regions(X_train_std,y_train,classifier=gnb)\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('sepal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
